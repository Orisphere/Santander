{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plot\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "training_data = pd.read_csv(\"train.csv\")\n",
    "testing_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.944923e+06</td>\n",
       "      <td>1.465493e+04</td>\n",
       "      <td>1.390895e+03</td>\n",
       "      <td>2.672245e+04</td>\n",
       "      <td>4.530164e+03</td>\n",
       "      <td>2.640996e+04</td>\n",
       "      <td>3.070811e+04</td>\n",
       "      <td>1.686522e+04</td>\n",
       "      <td>4.669208e+03</td>\n",
       "      <td>2.569407e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.676057e+05</td>\n",
       "      <td>4.446239e+05</td>\n",
       "      <td>8.056219e+05</td>\n",
       "      <td>7.812966e+05</td>\n",
       "      <td>143.529939</td>\n",
       "      <td>1.213809e+05</td>\n",
       "      <td>3.573451e+04</td>\n",
       "      <td>3.123741e+05</td>\n",
       "      <td>9.219960e+04</td>\n",
       "      <td>2.279100e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.234312e+06</td>\n",
       "      <td>3.893298e+05</td>\n",
       "      <td>6.428302e+04</td>\n",
       "      <td>5.699652e+05</td>\n",
       "      <td>2.359124e+05</td>\n",
       "      <td>1.514730e+06</td>\n",
       "      <td>5.770590e+05</td>\n",
       "      <td>7.512756e+05</td>\n",
       "      <td>1.879449e+05</td>\n",
       "      <td>9.610183e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.068038e+06</td>\n",
       "      <td>4.428889e+06</td>\n",
       "      <td>4.513246e+06</td>\n",
       "      <td>6.839451e+06</td>\n",
       "      <td>9584.318507</td>\n",
       "      <td>4.720709e+06</td>\n",
       "      <td>1.614622e+06</td>\n",
       "      <td>4.318501e+06</td>\n",
       "      <td>1.635993e+06</td>\n",
       "      <td>1.811139e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.260000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>1.480000e+07</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>2.070800e+07</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>1.040000e+07</td>\n",
       "      <td>3.196120e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>7.600000e+07</td>\n",
       "      <td>1.235880e+08</td>\n",
       "      <td>1.300000e+08</td>\n",
       "      <td>1.444000e+08</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>3.013120e+08</td>\n",
       "      <td>1.064200e+08</td>\n",
       "      <td>1.400000e+08</td>\n",
       "      <td>6.176800e+07</td>\n",
       "      <td>4.320000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             target     48df886f9     0deb4b6a8     34b15f335     a8cb14b00  \\\n",
       "count  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean   5.944923e+06  1.465493e+04  1.390895e+03  2.672245e+04  4.530164e+03   \n",
       "std    8.234312e+06  3.893298e+05  6.428302e+04  5.699652e+05  2.359124e+05   \n",
       "min    3.000000e+04  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    6.000000e+05  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    2.260000e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    8.000000e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    4.000000e+07  2.000000e+07  4.000000e+06  2.000000e+07  1.480000e+07   \n",
       "\n",
       "          2f0771a37     30347e683     d08d1fbe3     6ee66e115     20aa07010  \\\n",
       "count  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean   2.640996e+04  3.070811e+04  1.686522e+04  4.669208e+03  2.569407e+06   \n",
       "std    1.514730e+06  5.770590e+05  7.512756e+05  1.879449e+05  9.610183e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  6.000000e+05   \n",
       "max    1.000000e+08  2.070800e+07  4.000000e+07  1.040000e+07  3.196120e+08   \n",
       "\n",
       "           ...          3ecc09859     9281abeea     8675bec0b     3a13ed79a  \\\n",
       "count      ...       4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean       ...       4.676057e+05  4.446239e+05  8.056219e+05  7.812966e+05   \n",
       "std        ...       4.068038e+06  4.428889e+06  4.513246e+06  6.839451e+06   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max        ...       7.600000e+07  1.235880e+08  1.300000e+08  1.444000e+08   \n",
       "\n",
       "           f677d4d13     71b203550     137efaa80     fb36b89d9     7e293fbaf  \\\n",
       "count    4459.000000  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean      143.529939  1.213809e+05  3.573451e+04  3.123741e+05  9.219960e+04   \n",
       "std      9584.318507  4.720709e+06  1.614622e+06  4.318501e+06  1.635993e+06   \n",
       "min         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    640000.000000  3.013120e+08  1.064200e+08  1.400000e+08  6.176800e+07   \n",
       "\n",
       "          9fc776466  \n",
       "count  4.459000e+03  \n",
       "mean   2.279100e+05  \n",
       "std    1.811139e+06  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    4.320000e+07  \n",
       "\n",
       "[8 rows x 4992 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(training_data.describe())\n",
    "training_y = training_data[\"target\"]\n",
    "training_data = training_data.drop([\"target\", \"ID\"], axis=1)\n",
    "testing_ID = testing_data[\"ID\"]\n",
    "testing_data = testing_data.drop([\"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Identify highly correlated columns and constant columns and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  30347e683  \\\n",
      "48df886f9   1.000000   0.000815   0.001461   0.000723   0.000656   0.002004   \n",
      "0deb4b6a8   0.000815   1.000000   0.001015   0.000416   0.000377   0.001152   \n",
      "34b15f335   0.001461   0.001015   1.000000   0.000901   0.000818   0.002496   \n",
      "a8cb14b00   0.000723   0.000416   0.000901   1.000000   0.000335   0.001022   \n",
      "2f0771a37   0.000656   0.000377   0.000818   0.000335   1.000000   0.000928   \n",
      "\n",
      "           d08d1fbe3  6ee66e115  20aa07010  dc5a8f1d8    ...      3ecc09859  \\\n",
      "48df886f9   0.000845   0.002621   0.006629   0.003575    ...       0.004151   \n",
      "0deb4b6a8   0.000486   0.000538   0.003995   0.002116    ...       0.002488   \n",
      "34b15f335   0.001053   0.001165   0.017082   0.010173    ...       0.000338   \n",
      "a8cb14b00   0.000431   0.000477   0.005135   0.001878    ...       0.002208   \n",
      "2f0771a37   0.000391   0.000433   0.004663   0.001705    ...       0.002005   \n",
      "\n",
      "           9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
      "48df886f9   0.001789   0.006381   0.004301   0.014979   0.000968   0.000833   \n",
      "0deb4b6a8   0.002173   0.003863   0.002472   0.000324   0.000556   0.000479   \n",
      "34b15f335   0.004708   0.000233   0.005357   0.000702   0.001206   0.001038   \n",
      "a8cb14b00   0.001928   0.003428   0.002194   0.000288   0.000494   0.000425   \n",
      "2f0771a37   0.001751   0.003113   0.001992   0.000261   0.000448   0.000386   \n",
      "\n",
      "           fb36b89d9  7e293fbaf  9fc776466  \n",
      "48df886f9   0.002723   0.002106   0.004738  \n",
      "0deb4b6a8   0.027427   0.001220   0.002723  \n",
      "34b15f335   0.003386   0.002643   0.021261  \n",
      "a8cb14b00   0.001389   0.001082   0.002417  \n",
      "2f0771a37   0.001261   0.000983   0.002195  \n",
      "\n",
      "[5 rows x 4991 columns]\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = training_data.corr().abs()\n",
    "print(correlation_matrix.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n",
      "262\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "# Select upper triangle of correlation matrix to eliminate redundancies\n",
    "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.85\n",
    "to_drop_85 = [column for column in upper.columns if any(upper[column] > 0.85)]\n",
    "to_drop_90 = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "to_drop_95 = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(len(to_drop_85))\n",
    "print(len(to_drop_90))\n",
    "print(len(to_drop_95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features from the training and testing data\n",
    "training_data.drop(to_drop_85, axis=1, inplace=True)\n",
    "testing_data.drop(to_drop_85, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Rescale features using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(training_data)\n",
    "training_data = scaler.transform(training_data)\n",
    "testing_data = scaler.transform(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Split the trainging data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, training_y, \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RMSLE evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(groundtruth, predictions):\n",
    "    score = np.sqrt(np.square(np.log(groundtruth + 1) - np.log(predictions + 1)).mean())\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_submission(predictions, submission_num):\n",
    "    submission_path = \"submission_\" + str(submission_num) + \".csv\"\n",
    "    if os.path.exists(submission_path):\n",
    "        print(\"Path already exists, please use another submission number.\")\n",
    "    else:\n",
    "        final_csv = pd.DataFrame(testing_ID).join(pd.DataFrame(predictions, columns=[\"target\"]))\n",
    "        final_csv.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a baseline using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score\n",
      "1.546027959606595\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgdmat = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "our_params = {'eta':0.065,'seed':0,'subsample':1,'colsample_bytree':1,\n",
    "            'objective':'reg:linear','max_depth':25,'min_child_weight':1}\n",
    "final_gb = xgb.train(our_params,xgdmat)\n",
    "tesdmat = xgb.DMatrix(X_test)\n",
    "predictions = final_gb.predict(tesdmat)\n",
    "\n",
    "print(\"RMSLE score\")\n",
    "print(evaluate(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain with all the training data for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(training_data, training_y)\n",
    "\n",
    "our_params = {'eta':0.065,'seed':0,'subsample':1,'colsample_bytree':1,\n",
    "            'objective':'reg:linear','max_depth':25,'min_child_weight':1}\n",
    "final_gb = xgb.train(our_params,xgdmat)\n",
    "finaldmat = xgb.DMatrix(testing_data)\n",
    "final_predictions = final_gb.predict(finaldmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score\n",
      "1.702122998005553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR(degree=3, C=0.01)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "predictions = svr.predict(X_test)\n",
    "print(\"RMSLE score\")\n",
    "print(evaluate(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07083221 0.112185   0.14347006 ... 0.99000177 0.99003366 0.99006525]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1750, random_state=42).fit(X_train)\n",
    "\n",
    "# Apply pca transformation to the training and testing data\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Show how much of the total variance is captured by the PCA transformation.\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use xgboost on the PCA-transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score\n",
      "1.58479800455529\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgdmat = xgb.DMatrix(X_train_pca, y_train)\n",
    "our_params = {'eta':0.065,'seed':0,'subsample':1,'colsample_bytree':1,\n",
    "            'objective':'reg:linear','max_depth':10,'min_child_weight':1}\n",
    "final_gb = xgb.train(our_params, xgdmat)\n",
    "tesdmat = xgb.DMatrix(X_test_pca)\n",
    "predictions = final_gb.predict(tesdmat)\n",
    "\n",
    "print(\"RMSLE score\")\n",
    "print(evaluate(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols, hidden_units=[1000, 500, 200, 50], model_dir=\"/santander_models\")\n",
    "\n",
    "regressor.train(input_fn=get_input_fn(training_set), steps=5000)\n",
    "\n",
    "ev = regressor.evaluate(input_fn=get_input_fn(test_set, num_epochs=1, shuffle=False))\n",
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))\n",
    "\n",
    "y = regressor.predict(input_fn=get_input_fn(prediction_set, num_epochs=1, shuffle=False))\n",
    "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
